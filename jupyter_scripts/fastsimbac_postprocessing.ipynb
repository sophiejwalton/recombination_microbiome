{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import scipysssssssssssssssssss\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir = '/Users/Device6/Documents/Research/bgoodlab/fastsimbac/fastSimBac_mac/results'\n",
    "data_dir = os.path.join(config.analysis_directory, 'fastsimbac_data')\n",
    "fig_dir = os.path.join(config.analysis_directory, 'run_size_survival_distributions', 'fastSimBac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    f = open(os.path.join(data_dir, filename), 'r')\n",
    "    data = []\n",
    "    for line in f.read().splitlines()[:-5]:\n",
    "        parts = line.split('\\t')\n",
    "        if len(parts) != 5:\n",
    "            continue\n",
    "        line_data = list(map(int, parts[-1]))\n",
    "        line_data.append(float(parts[2]))\n",
    "        data.append(line_data)\n",
    "    f.close()\n",
    "    return np.array(data)\n",
    "        \n",
    "def compare_two_samples(idx1, idx2, data, genome_len):\n",
    "    locations = data[:, -1][np.nonzero(data[:, idx1] != data[:, idx2])]\n",
    "    runs = locations[1:] - locations[:-1]\n",
    "    runs = runs * genome_len\n",
    "    return locations, runs.astype(int)\n",
    "\n",
    "def get_block_snp_vector(idx1, idx2, data, genome_len=1e6, block_len=1e3):\n",
    "    bins = np.arange(0, genome_len + 1, block_len)\n",
    "    locations = data[:, -1][np.nonzero(data[:, idx1] != data[:, idx2])] * genome_len\n",
    "    snp_vec, _ = np.histogram(locations, bins)\n",
    "    return snp_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_null(ax):\n",
    "    # plot the unlinked null\n",
    "    p = 0.01\n",
    "    snps = np.random.binomial(1, p, size=int(1e6))\n",
    "    locations = np.where(snps == 1)[0]\n",
    "    run_lengths = locations[1:] - locations[:-1]\n",
    "    p_emp = sum(snps) / 1e6\n",
    "    _ = ax.hist(run_lengths * p_emp, density=True, bins=50, cumulative=-1, histtype='step', color='k')\n",
    "    ax.plot([], color='k', label='independent null')\n",
    "\n",
    "\n",
    "def plot_one_simulation(ax, filename, genome_len=1e6, num_curves=500, color='b', label=None, cutoff=None):\n",
    "    data = load_data(filename)\n",
    "    \n",
    "    sample_size = data.shape[1] - 1\n",
    "    pairs = [random.sample(range(sample_size), 2) for i in range(num_curves)]\n",
    "\n",
    "    # plot the simulation\n",
    "    divergences = []\n",
    "    for pair in pairs:\n",
    "        snp_locs, run_lens = compare_two_samples(pair[0], pair[1], data, genome_len)\n",
    "        snp_count = len(snp_locs)\n",
    "        div = snp_count / genome_len\n",
    "        divergences.append(div)\n",
    "        if cutoff:\n",
    "            if div < cutoff:\n",
    "                continue\n",
    "        _ = ax.hist(run_lens * div, bins=100, cumulative=-1, histtype='step', color=color, density=True, alpha=0.1)\n",
    "    ax.plot([], color=color, label=label)\n",
    "    return np.array(divergences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run lengths distribution plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_len = 1e6\n",
    "plt.figure(figsize=(8,6), dpi=600)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_yscale('log')\n",
    "\n",
    "plot_null(ax)\n",
    "\n",
    "colors = sns.color_palette()\n",
    "\n",
    "all_divs = []\n",
    "\n",
    "ax.set_xlim([0, 25])\n",
    "\n",
    "rs = [0.005, 0.01, 0.02]\n",
    "ts = [0.001, 0.005, 0.01]\n",
    "ls = [1000, 5000, 10000, 20000]\n",
    "r = rs[2]\n",
    "t = ts[2]\n",
    "for j in range(1):\n",
    "    lam = ls[j]\n",
    "    filename = 'parameter_space/num_samples_100_genomelen_1e+06_r_%.3f_t_%.3f_tractlen_%d.txt' % (r, t, lam)\n",
    "    divs = plot_one_simulation(ax, filename, num_curves=100, color=colors[j], label='l=%d'%lam, cutoff=0.8 * t)\n",
    "    all_divs.append(divs)\n",
    "\n",
    "ax.set_title('Bacterial Sequential Markov Coalescence')\n",
    "ax.set_xlabel('Rescaled run lengths')\n",
    "ax.set_ylabel('Survival proba')\n",
    "ax.legend()\n",
    "\n",
    "#plt.savefig(os.path.join(fig_dir, 'num_samples_100_genomelen_1e+06_r_%.3f_t_%.3f.pdf'%(r, t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize=(12, 9), dpi=600)\n",
    "\n",
    "rs = [0.005, 0.01, 0.02]\n",
    "ts = [0.001, 0.005, 0.01]\n",
    "ls = [1000, 5000, 10000, 20000]\n",
    "\n",
    "colors = sns.color_palette()\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax = axs[i, j]\n",
    "        ax.set_xlim([0, 25])\n",
    "        ax.set_yscale('log')\n",
    "        plot_null(ax)\n",
    "        r = rs[i]\n",
    "        t = ts[j]\n",
    "        for k in range(len(ls)):\n",
    "            lam = ls[k]\n",
    "            filename = 'parameter_space/num_samples_100_genomelen_1e+06_r_%.3f_t_%.3f_tractlen_%d.txt' % (r, t, lam)\n",
    "            try:\n",
    "                divs = plot_one_simulation(ax, filename, num_curves=100, color=colors[k], label='l=%d'%lam, cutoff=0.8 * t)\n",
    "            except IOError:\n",
    "                print(\"Skipping bad r_%.3f_t_%.3f_tractlen_%d\" % (r, t, lam))\n",
    "                continue\n",
    "        ax.legend()\n",
    "for i in range(3):\n",
    "    axs[i, 0].set_ylabel('r=%.3f'%rs[i])\n",
    "    axs[0, i].set_title('t=%.3f'%ts[i])\n",
    "axs[2, 1].set_xlabel('Normalized run lengths')\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(fig_dir, 'param_scan.pdf'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Investigate the peak\n",
    "data = load_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    idx1, idx2 = random.sample(range(100), 2)\n",
    "    snp_vec = get_block_snp_vector(idx1, idx2, data)\n",
    "    div = np.sum(snp_vec) / 1e6\n",
    "    if div > 0.01:\n",
    "        continue\n",
    "    else:\n",
    "        print(div)\n",
    "        plt.plot(snp_vec)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(snp_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clonal simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "genome_len = 1e6\n",
    "for i in range(1, 11):\n",
    "    divergences = []\n",
    "    pairs = []\n",
    "    filename = 'clonal/100/num_samples_100_genomelen_1e+06_r_0.000_t_0.010_tractlen_5000_rep_{}.txt'.format(i)\n",
    "    sim_data = load_data(filename)\n",
    "    for i in range(sample_size - 1):\n",
    "        for j in range(i + 1, sample_size):\n",
    "            snp_locs, run_lens = compare_two_samples(i, j, sim_data, genome_len)\n",
    "            snp_count = len(snp_locs) + 1\n",
    "            div = snp_count / genome_len\n",
    "            divergences.append(div)\n",
    "            pairs.append((i, j))\n",
    "    divergences = np.array(divergences)\n",
    "    pairs = np.array(pairs)\n",
    "\n",
    "    plt.figure()\n",
    "    sns.distplot(divergences, bins=100, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_bins = np.arange(0, 1e6 + 1, 1000)\n",
    "clonal_counts = []\n",
    "recomb_counts = []\n",
    "clonal_threshold = 1\n",
    "for pair in pairs[np.nonzero(divergences < 0.0005)[0]]:\n",
    "    snp_locs, run_lens = compare_two_samples(pair[0], pair[1], sim_data, genome_len)\n",
    "    snps = snp_locs * genome_len\n",
    "    histo = np.histogram(snps.astype(int), bins=gene_bins)\n",
    "    snp_genes = histo[0]\n",
    "    clonal_counts.append(len(np.nonzero((snp_genes <= clonal_threshold) & (snp_genes !=0))[0]))\n",
    "    recomb_counts.append(len(np.nonzero(snp_genes > clonal_threshold)[0]))\n",
    "    #plt.figure()\n",
    "    #plt.plot(histo[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(clonal_counts, recomb_counts, '.')\n",
    "slope, intercept, _, _, _ = scipy.stats.linregress(clonal_counts, recomb_counts)\n",
    "xs = np.linspace(0, max(clonal_counts), 100)\n",
    "plt.plot(xs, slope * xs + intercept, label=\"slope=%f\"%slope)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(divergences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(divergences, bins=200, kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Pairwise clonal simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "divergences = []\n",
    "for i in range(1, 5001):\n",
    "    filename = 'clonal/num_samples_2_genomelen_1e+06_r_0.000_t_0.010_tractlen_5000_rep_{}.txt'.format(i)\n",
    "    sim_data = load_data(filename)\n",
    "    snp_locs, run_lens = compare_two_samples(0, 1, sim_data, genome_len)\n",
    "    snp_count = len(snp_locs) + 1\n",
    "    div = snp_count / genome_len\n",
    "    divergences.append(div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(divergences, kde=False, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coarse-graining into blocks (fake genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/Device6/Documents/Research/bgoodlab/microbiome_evolution/')\n",
    "from utils import HGT_utils\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = 'parameter_space/num_samples_100_genomelen_1e+06_r_0.005_t_0.001_tractlen_1000.txt'\n",
    "data = load_data(filename1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs_map = dict()\n",
    "snp_counts_map = dict()\n",
    "for i in range(100):\n",
    "    for j in range(i+1, 100):\n",
    "        snp_vec = get_block_snp_vector(i, j, data, genome_len=1e6, block_len=1e3)\n",
    "        res = HGT_utils.find_runs(snp_vec)\n",
    "        all_runs_map[(i, j)] = res\n",
    "        snp_counts_map[(i, j)] = sum(snp_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0, 5, 10, 15]\n",
    "final_cumu_runs = HGT_utils.cumulate_runs_by_thresholds(\n",
    "    all_runs_map, snp_counts_map, (-1, 1e6), 1000, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "for i in range(len(thresholds)):\n",
    "    ax.plot(final_cumu_runs[i], label=\"Threshold %d\" % thresholds[i])\n",
    "    print(max(final_cumu_runs[i]))\n",
    "ax.legend()\n",
    "ax.set_ylim((0, len(all_runs_map)))\n",
    "ax.figure.set_size_inches(12, 4)\n",
    "ax.set_title('Cumulative long runs per gene')\n",
    "ax.set_xlabel('Gene id')\n",
    "ax.set_ylabel('Num runs')\n",
    "#fig.savefig(os.path.join(config.analysis_directory, 'IBS_locations', 'synthetic/recombinant_r_0.010_t_0.010_tractlen_500.pdf'), dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(os.path.join(data_dir, \"parameter_space\")):\n",
    "    if filename.startswith('.'):\n",
    "        continue\n",
    "    else:\n",
    "        filename_base = filename.split('.')[0]\n",
    "        data = load_data(os.path.join(\"parameter_space\", filename))\n",
    "        \n",
    "        all_runs_map = dict()\n",
    "        snp_counts_map = dict()\n",
    "        for i in range(100):\n",
    "            for j in range(i+1, 100):\n",
    "                snp_vec = get_block_snp_vector(i, j, data, genome_len=1e6, block_len=1e3)\n",
    "                res = HGT_utils.find_runs(snp_vec)\n",
    "                all_runs_map[(i, j)] = res\n",
    "                snp_counts_map[(i, j)] = sum(snp_vec)\n",
    "                \n",
    "        thresholds = [0, 5, 10, 15]\n",
    "        final_cumu_runs = HGT_utils.cumulate_runs_by_thresholds(\n",
    "            all_runs_map, snp_counts_map, (-1, 1e6), 1000, thresholds)\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        ax = plt.gca()\n",
    "        for i in range(len(thresholds)):\n",
    "            ax.plot(final_cumu_runs[i], label=\"Threshold %d\" % thresholds[i])\n",
    "            print(max(final_cumu_runs[i]))\n",
    "        ax.legend()\n",
    "        ax.set_ylim((0, len(all_runs_map)))\n",
    "        ax.figure.set_size_inches(12, 4)\n",
    "        ax.set_title('Cumulative long runs per gene')\n",
    "        ax.set_xlabel('Gene id')\n",
    "        ax.set_ylabel('Num runs')\n",
    "        fig.savefig(os.path.join(\n",
    "            config.analysis_directory, 'IBS_locations', 'synthetic', \"parameter_space\",\n",
    "        \"%s.png\"%filename), dpi=600)\n",
    "        plt.close()\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        ax = plt.gca()\n",
    "        ax.set_xlim([0, 1])\n",
    "        for i in range(1, 4):\n",
    "            _ = ax.hist(final_cumu_runs[i] / final_cumu_runs[0], cumulative=-1,\n",
    "                        bins=100, density=True, label=\"Threshold %d\" % thresholds[i])\n",
    "        ax.legend()\n",
    "        fig.savefig(os.path.join(\n",
    "            config.analysis_directory, 'IBS_locations', 'synthetic', \"ratios\",\n",
    "        \"%s.png\"%filename), dpi=600)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polarize data\n",
    "genotype = np.sum(data[:, :100], axis=1).astype(int) / 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarized_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarized_data[genotype == 1] = 1 - data[genotype == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marked_haplotypes = np.zeros((data.shape[1] - 1, 999 + data.shape[0], 3))\n",
    "snp_idx = 0\n",
    "block_size = 1000\n",
    "curr_block = 0\n",
    "block_snps = {}\n",
    "block_snps[0] = []\n",
    "for i in range(data.shape[0]):\n",
    "    location = data[i, -1] * 1e6\n",
    "    if int(location) / block_size > curr_block:\n",
    "        marked_haplotypes[:, snp_idx, 1] = 1\n",
    "        block_snps[curr_block] = np.array(block_snps[curr_block])\n",
    "        snp_idx += 1\n",
    "        curr_block += 1\n",
    "        block_snps[curr_block] = []\n",
    "    marked_haplotypes[:, snp_idx, 0] = polarized_data[i, :-1]\n",
    "    marked_haplotypes[:, snp_idx, 2] = 1 - polarized_data[i, :-1]\n",
    "    block_snps[curr_block].append(polarized_data[i, :-1])\n",
    "    snp_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(data[100, -1] * 1e6) / block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_snps[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marked_haplotypes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches((60, 4))\n",
    "plt.imshow(marked_haplotypes[flat_array, :500, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_divergence(haplotype_arr):\n",
    "    # haplotype_arr: (num_sites, num_samples)\n",
    "    num_samples = haplotype_arr.shape[1]\n",
    "    dm = np.zeros((num_samples, num_samples))\n",
    "    for i in range(num_samples):\n",
    "        for j in range(i+1, num_samples):\n",
    "            dm[i, j] = np.sum(haplotype_arr[:, i] != haplotype_arr[:, j])\n",
    "            dm[j, i] = np.sum(haplotype_arr[:, i] != haplotype_arr[:, j])\n",
    "    return dm\n",
    "\n",
    "def matrix_to_clusters(distance_matrix, allowed_snps=0):\n",
    "    # return a list of list of indices. Each sublist is a cluster of haplotypes\n",
    "    G = nx.from_numpy_matrix(distance_matrix <= allowed_snps)\n",
    "    clusters = get_cluster_members(G)\n",
    "    return [list(c) for c in clusters]\n",
    "\n",
    "def get_cluster_members(G):\n",
    "    sub_graphs = nx.connected_component_subgraphs(G)\n",
    "    clusters = []\n",
    "    for i, sg in enumerate(sub_graphs):\n",
    "        clusters.append(sg.nodes)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_m = pairwise_divergence(block_snps[6])\n",
    "print(dist_m[0, 1])\n",
    "clusters = matrix_to_clusters(dist_m)\n",
    "cluster_sizes = [len(x) for x in clusters]\n",
    "shared_pairs = np.sum([x*(x-1)/2 for x in cluster_sizes])\n",
    "print(shared_pairs)\n",
    "print(final_cumu_runs[0][6])\n",
    "flat_array = np.array([x for c in clusters for x in c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "for i in range(1000):\n",
    "    dist_m = pairwise_divergence(block_snps[i])\n",
    "    _ = ax.hist(dist_m.flatten(), cumulative=-1, histtype='step', alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(final_cumu_runs[0], bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Getting local trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from Bio import Phylo\n",
    "from cStringIO import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filename = 'trees.txt'\n",
    "data_dir = '/Users/Device6/Documents/Research/bgoodlab/fastsimbac/fastSimBac_mac/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f = open(os.path.join(data_dir, filename))\n",
    "f.seek(0)\n",
    "tree = Phylo.read(StringIO(tree_str), 'newick')\n",
    "Phylo.draw(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def newick_to_matrix(newick_str):\n",
    "    tree = Phylo.read(StringIO(newick_str), 'newick')\n",
    "    num_leaves = len(tree.get_terminals())\n",
    "    distance = np.zeros((num_leaves, num_leaves))\n",
    "    for x, y in itertools.combinations(tree.get_terminals(), 2):\n",
    "        i = int(x.name)\n",
    "        j = int(y.name)\n",
    "        distance[i, j] = tree.distance(x, y)\n",
    "    return distance\n",
    "\n",
    "def parse_line(line_str):\n",
    "    s = line.split(';')[0]\n",
    "    length = int(s[1:s.find(']')])\n",
    "    tree_str = s[s.find(']')+1:]\n",
    "    return length, tree_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "loc = 0\n",
    "tree_idx = 0\n",
    "for line in f:\n",
    "    if not line.startswith('['):\n",
    "        continue\n",
    "    l, tree_str = parse_line(line)\n",
    "    with open('./trees/{}_{}.txt'.format(tree_idx, l), 'w') as save:\n",
    "        save.write(tree_str)\n",
    "    loc += l\n",
    "    tree_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Experiment with Zarr saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/Users/Device6/Documents/Research/bgoodlab/fastsimbac/'\n",
    "csv_dir = os.path.join(data_dir, 'postprocessing', 'matrices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filenames = filter(lambda x: not x.startswith('.'), os.listdir(csv_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filenames = sorted(filenames, key=lambda x: int(x.split('_')[0]))\n",
    "spans = np.array(map(lambda x: int(re.findall('_([0-9]+).', x)[0]), filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "zz = zarr.open('data/example.zarr', mode='w', shape=(100, 100, len(spans)), chunks=(10, 10, 100), dtype='i4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "curr_loc=0\n",
    "for i, name in enumerate(filenames):\n",
    "    span = int(re.findall('_([0-9]+).', name)[0])\n",
    "    arr = np.loadtxt(os.path.join(csv_dir, name), delimiter=',')\n",
    "    z1[:, :, i] = arr\n",
    "    if i > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "arr = np.loadtxt(os.path.join(csv_dir, filenames[0]), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = np.zeros((100, 100, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a[:, :, :3] = np.repeat(arr[:, :, None], 3, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "curr_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('spans.txt', spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
